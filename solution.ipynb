{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from scipy.ndimage.measurements import label\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# NOTE: the next import is only valid \n",
    "# for scikit-learn version <= 0.17\n",
    "# if you are using scikit-learn >= 0.18 then use this:\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_size=(32, 32)\n",
    "hist_bins=32\n",
    "orient=9\n",
    "pix_per_cell=8 \n",
    "cell_per_block=2 \n",
    "hog_channel=0\n",
    "                     \n",
    "spatial_feat=True\n",
    "hist_feat=True\n",
    "hog_feat=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "veh_gti_far length: 834\nveh_gti_l length: 909\nveh_gti_far length: 419\nveh_gti_far length: 664\nveh_gti_far length: 5966\nnonveh_extras length: 5068\nnonveh_gti length: 3900\nTotal Vehicles: 8792 Total Non Vehicles: 8968\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "# path_dataset_vehicle = ./dataset/vehicles\n",
    "# path_dataset_nonvehicle = ./dataset/non-vehicles\n",
    "\n",
    "# vehicles\n",
    "\n",
    "veh_gti_far = glob.glob('./dataset/vehicles/GTI_Far/*.png')\n",
    "veh_gti_l = glob.glob('./dataset/vehicles/GTI_Left/*.png')\n",
    "veh_gti_mid_close = glob.glob('./dataset/vehicles/GTI_MiddleClose/*.png')\n",
    "veh_gti_r = glob.glob('./dataset/vehicles/GTI_Right/*.png')\n",
    "veh_kitti = glob.glob('./dataset/vehicles/KITTI_extracted/*.png')\n",
    "\n",
    "#non vehicles\n",
    "nonveh_extras = glob.glob('./dataset/non-vehicles/Extras/*.png')\n",
    "nonveh_gti = glob.glob('./dataset/non-vehicles/GTI/*.png')\n",
    "\n",
    "# evaluate the dataset\n",
    "len_veh_gti_far = len(veh_gti_far)\n",
    "len_veh_gti_l = len(veh_gti_l)\n",
    "len_veh_gti_mid_close = len(veh_gti_mid_close)\n",
    "len_veh_gti_r = len(veh_gti_r)\n",
    "len_veh_kitti = len(veh_kitti)\n",
    "len_all_veh = len_veh_gti_far + len_veh_gti_l + len_veh_gti_mid_close \\\n",
    "    + len_veh_gti_r + len_veh_kitti\n",
    "\n",
    "\n",
    "len_nonveh_extras = len(nonveh_extras)\n",
    "len_nonveh_gti = len(nonveh_gti)\n",
    "len_all_non_veh =len_nonveh_extras+len_nonveh_gti\n",
    "\n",
    "print('veh_gti_far length: {}' .format(len_veh_gti_far))\n",
    "print('veh_gti_l length: {}' .format(len_veh_gti_l))\n",
    "print('veh_gti_far length: {}' .format(len_veh_gti_mid_close))\n",
    "print('veh_gti_far length: {}' .format(len_veh_gti_r))\n",
    "print('veh_gti_far length: {}' .format(len_veh_kitti))\n",
    "print('nonveh_extras length: {}' .format(len_nonveh_extras))\n",
    "print('nonveh_gti length: {}' .format(len_nonveh_gti))\n",
    "\n",
    "print('Total Vehicles: {} Total Non Vehicles: {}' .format(len_all_veh,len_all_non_veh ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# shuffle and split the data \n",
    "all_veh = veh_gti_far + veh_gti_l + veh_gti_mid_close \\\n",
    "    + veh_gti_r + veh_kitti\n",
    "\n",
    "all_non_veh = nonveh_extras + nonveh_gti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plt.rcParams['figure.figsize'] = (20,20)\n",
    "# plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "# matplotlib.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "\n",
    "#print ('rows: {}' .format(rows))\n",
    "\n",
    "n_examples = 5\n",
    "columns = 2\n",
    "w = 16\n",
    "h = 16\n",
    "# fig=plt.figure(figsize=(180, 160), dpi= 80, facecolor='w', edgecolor='k')\n",
    "fig, axes = plt.subplots(n_examples,columns, figsize=(w,h))\n",
    "axes = axes.ravel()\n",
    "for i in range(len(axes)):\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "# iterate through the classes and pull together useful information\n",
    "for i in range(n_examples): \n",
    "    axes[i * 2].imshow(mpimg.imread(all_veh[np.random.randint(0,len(all_veh)-1)]))\n",
    "    axes[i * 2].set_title('vehicle')\n",
    "    axes[i * 2 +1].imshow(mpimg.imread(all_non_veh[np.random.randint(0,len(all_non_veh)-1)]))\n",
    "    axes[i * 2 +1].set_title('non vehicle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False,\n",
    "                                  visualise=True, feature_vector=False)\n",
    "        return features, hog_image\n",
    "    else:\n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False,\n",
    "                       visualise=False, feature_vector=feature_vec)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_figure(array_to_plot, labels_array, n_rows, n_columns, figuresize=(64,64),colourmap='gray'):\n",
    "    fig, axes = plt.subplots( n_rows, n_columns,figsize=figuresize)\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i in range(len(array_to_plot)):\n",
    "        print('i {}'.format(i))\n",
    "        print('title {}'.format(labels_array[i]))\n",
    "        axes[i].imshow(array_to_plot[i], cmap=colourmap)\n",
    "        axes[i].set_title(labels_array[i])\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    # TODO Reinstate\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig('./output_images/dataset_samples.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def explore_hog(veh_img,gray):\n",
    "\n",
    "    %matplotlib inline\n",
    "    plt.rcParams['figure.figsize'] = (20,20)\n",
    "    \n",
    "    print ('function to visualise the dataset and hog output')\n",
    "\n",
    "    i=0\n",
    "    rows = 2\n",
    "    columns = 4\n",
    "    w = 16\n",
    "    h = 16\n",
    "    \n",
    "    # fig=plt.figure(figsize=(180, 160), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    fig, axes = plt.subplots(rows,columns, figsize=(w,h))\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(hspace = .1, wspace=.5)    \n",
    "    \n",
    "    axes = axes.ravel()\n",
    "    # for i in range(len(axes)):\n",
    "    #     axes[i].axis('off')\n",
    "        \n",
    "    # iterate through the classes and pull together useful information\n",
    "    # for i in range(n_examples): \n",
    "    # veh_img = mpimg.imread(all_veh[rnd])\n",
    "    axes[i*0].set_title('vehicle')   \n",
    "    axes[i*0].imshow(veh_img)\n",
    "\n",
    "    axes[i*4+1].set_title('chn0')     \n",
    "    axes[i*4+1].imshow(veh_img[:,:,0], cmap='gray')\n",
    "    axes[i*4+2].set_title('chn1')\n",
    "    axes[i*4+2].imshow(veh_img[:,:,1], cmap='gray')\n",
    "    axes[i*4+3].set_title('chn2')     \n",
    "    axes[i*4+3].imshow(veh_img[:,:,2], cmap='gray')\n",
    "       \n",
    "\n",
    "    \n",
    "    i+=1\n",
    "    features, hog_image = get_hog_features(gray, orient,\n",
    "                                           pix_per_cell, cell_per_block,\n",
    "                                           vis=True, feature_vec=False)\n",
    "    axes[i*4].set_title('gray')    \n",
    "    axes[i*4].imshow(hog_image, cmap='gray')\n",
    "    \n",
    "    features, hog_image = get_hog_features(veh_img[:,:,0], orient,\n",
    "                                           pix_per_cell, cell_per_block,\n",
    "                                           vis=True, feature_vec=False)\n",
    "    axes[i*4+1].set_title('chn0')    \n",
    "    axes[i*4+1].imshow(hog_image, cmap='gray')\n",
    "      \n",
    "    features, hog_image = get_hog_features(veh_img[:,:,1], orient,\n",
    "                                           pix_per_cell, cell_per_block,\n",
    "                                           vis=True, feature_vec=False)\n",
    "    axes[i*4+2].set_title('chn1')    \n",
    "    axes[i*4+2].imshow(hog_image, cmap='gray')\n",
    "\n",
    "    features, hog_image = get_hog_features(veh_img[:,:,2], orient,\n",
    "                                           pix_per_cell, cell_per_block,\n",
    "                                           vis=True, feature_vec=False)\n",
    "    axes[i*4+3].set_title('chn2')    \n",
    "    axes[i*4+3].imshow(hog_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_color(img, cspace='YCrCb'):\n",
    "    if cspace != 'RGB':\n",
    "        if cspace == 'HSV':\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif cspace == 'LUV':\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif cspace == 'HLS':\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif cspace == 'YUV':\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif cspace == 'YCrCb':\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "        elif cspace == 'LAB':\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2LAB) \n",
    "    else: \n",
    "        return np.copy(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define a function to compute binned color features  \n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define a function to compute color histogram features  \n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_features_from_course(files, cspace='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, hist_range=(0, 256)):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in files:\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        feature_image = convert_color(img, cspace)\n",
    "        \n",
    "        # if cspace != 'RGB':\n",
    "        #     if cspace == 'HSV':\n",
    "        #         feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        #     elif cspace == 'LUV':\n",
    "        #         feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "        #     elif cspace == 'HLS':\n",
    "        #         feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "        #     elif cspace == 'YUV':\n",
    "        #         feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "        # else: feature_image = np.copy(image)      \n",
    "        # Apply bin_spatial() to get spatial color features\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        # Apply color_hist() also with a color space option now\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins, bins_range=hist_range)\n",
    "        # Append the new feature vector to the features list\n",
    "        features.append(np.concatenate((spatial_features, hist_features)))\n",
    "    # Return list of feature vectors\n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_imgs_features(files, cspace='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True): \n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in files:\n",
    "        img = mpimg.imread(file)\n",
    "        # plt.imshow(img)\n",
    "        features.append(single_img_features(img, cspace=cspace, spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=hog_channel,\n",
    "                        spatial_feat=False, hist_feat=False, hog_feat=True))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end of cell\n"
     ]
    }
   ],
   "source": [
    "# Define a function to extract features from a single image window\n",
    "# This function is very similar to extract_features()\n",
    "# just for a single image rather than list of images\n",
    "def single_img_features(img, cspace='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9,\n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=False, hog_feat=True, hist_feat=False):    \n",
    "    #1) Define an empty list to receive features\n",
    "    img_features = []\n",
    "    # print('image shape: {}' .format(img.shape))\n",
    "    \n",
    "    #2) Apply color conversion if other than 'RGB'\n",
    "    #TODO replace with a call to convert colour\n",
    "    feature_image = convert_color(img, cspace)   \n",
    "    # if color_space != 'RGB':\n",
    "    #     if color_space == 'HSV':\n",
    "    #         feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    #     elif color_space == 'LUV':\n",
    "    #         feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "    #     elif color_space == 'HLS':\n",
    "    #         feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    #     elif color_space == 'YUV':\n",
    "    #         feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    #     elif color_space == 'YCrCb':\n",
    "    #         feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    # else: feature_image = np.copy(img)      \n",
    "    #3) Compute spatial features if flag is set\n",
    "    if spatial_feat == True:\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        #4) Append features to list\n",
    "        img_features.append(spatial_features)\n",
    "    #5) Compute histogram features if flag is set\n",
    "    if hist_feat == True:\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "        #6) Append features to list\n",
    "        img_features.append(hist_features)\n",
    "    #7) Compute HOG features if flag is set\n",
    "    if hog_feat == True:\n",
    "        # print('hog_feat')\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                # print('Using ALL channels'.format(hog_channel))\n",
    "                hog_features.extend(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))      \n",
    "        else:\n",
    "            # print('Using single channel: {}'.format(hog_channel))\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        #8) Append features to list\n",
    "        img_features.append(hog_features)\n",
    "        # print('img_features len: {}' .format(len(img_features)))\n",
    "\n",
    "    #9) Return concatenated array of features\n",
    "    return np.concatenate(img_features)\n",
    "\n",
    "print('end of cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    \n",
    "    # Split up data into randomized training and test sets\n",
    "    rand_state = np.random.randint(0, 100)\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(\n",
    "    #     scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=rand_state)\n",
    "    \n",
    "    print('X_train len: {}' .format(len(X_train)))\n",
    "    print('X_test len: {}' .format(len(X_test)))\n",
    "    print('X_test len: {}' .format(len(X_test)))\n",
    "    print('y_test len: {}' .format(len(y_test)))\n",
    "    # \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(cspace, hog_channel ):\n",
    "    # print('extracting features')\n",
    "    car_features = extract_imgs_features(cars, cspace=cspace, spatial_size=(32, 32),\n",
    "                            hist_bins=32, orient=9, \n",
    "                            pix_per_cell=8, cell_per_block=2, hog_channel=hog_channel,\n",
    "                            spatial_feat=False, hist_feat=False, hog_feat=True)\n",
    "    notcar_features = extract_imgs_features(notcars, cspace=cspace, spatial_size=(32, 32),\n",
    "                            hist_bins=32, orient=9, \n",
    "                            pix_per_cell=8, cell_per_block=2, hog_channel=hog_channel,\n",
    "                            spatial_feat=False, hist_feat=False, hog_feat=True)\n",
    "    print('done extracting features')\n",
    "    # Create an array stack of feature vectors\n",
    "    X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "    \n",
    "    # # Fit a per-column scaler\n",
    "    # X_scaler = StandardScaler().fit(X)\n",
    "    # # Apply the scaler to X\n",
    "    # scaled_X = X_scaler.transform(X)\n",
    "    \n",
    "    print('features len: {}'.format(len(car_features)))\n",
    "    print('features shape: {}'.format(len(car_features[0].shape)))\n",
    "    # Define the labels vector\n",
    "    y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.95 Seconds to train SVC...\nTest Accuracy of SVC =  0.9603\n"
     ]
    }
   ],
   "source": [
    "def train_svc(X_train, y_train, X_test, y_test, svc):\n",
    "\n",
    "    t=time.time()\n",
    "    svc.fit(X_train, y_train)\n",
    "    t2 = time.time()\n",
    "    train_time = round(t2-t, 2)\n",
    "    print(train_time, 'Seconds to train SVC...')\n",
    "    # Check the score of the SVC\n",
    "    acc =  round(svc.score(X_test, y_test), 4)\n",
    "    print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "    # Check the prediction time for a single sample\n",
    "    t=time.time()\n",
    "    return svc, acc, train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_svn(X_test, y_test, svc):\n",
    "    n_predict = 10\n",
    "    t=time.time()\n",
    "    print('My SVC predicts: \\t', svc.predict(X_test[0:n_predict]))\n",
    "    print('For these',n_predict, 'labels: \\t', y_test[0:n_predict])\n",
    "    t2 = time.time()\n",
    "    print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')\n",
    "    return svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(cspace, hog_channel, svc):\n",
    "    \n",
    "    print('-----------------------------------------------------------')\n",
    "    msg = ('Colourspace: {}, hog channel: {}' .format(cspace, hog_channel))\n",
    "    print(msg)\n",
    "    X, y = get_features(cspace, hog_channel )\n",
    "    X_train, X_test, y_train, y_test = split_dataset(X,y)\n",
    "    \n",
    "    # Use a linear SVC \n",
    "    # print('creating svc')\n",
    "    # svc = LinearSVC()\n",
    "    # print('done creating svc')\n",
    "    svc, acc,train_time = train_svc(X_train, y_train, X_test, y_test, svc)\n",
    "    svc = predict_svn(X_test, y_test, svc)\n",
    "    msg = msg + '- \\taccuracy: {}' .format(acc) + '\\ttrain time: {}' .format(train_time)\n",
    "    print(msg)\n",
    "    return svc, X, y\n",
    "    print('-----------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\nextracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\georg\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\skimage\\feature\\_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done extracting features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features len: 8792\nfeatures shape: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train len: 14208\nX_test len: 3552\nX_test len: 3552\ny_test len: 3552\ncreating svc\ndone creating svc\ndone\n"
     ]
    }
   ],
   "source": [
    "# TODO play with these values to see how your classifier\n",
    "# performs under different binning scenarios\n",
    "spatial = 32\n",
    "histbin = 32\n",
    "\n",
    "print('running')\n",
    "cars = all_veh\n",
    "notcars = all_non_veh\n",
    "\n",
    "\n",
    "global_colour_space = 'HLS'\n",
    "global_channel = 'ALL'\n",
    "X = None\n",
    "y = None\n",
    "\n",
    "# train_predict('YCrCb', 'ALL')\n",
    "svc = LinearSVC()\n",
    "sandbox = False\n",
    "if sandbox:\n",
    "    cspaces =  ['RGB', 'HLS', 'HSV', 'YUV', 'LUV', 'YCrCb', 'LAB']\n",
    "    channels =  ['ALL', 0, 1,2]\n",
    "\n",
    "    for cspace in cspaces:\n",
    "        for channel in channels:\n",
    "        # call the svn\n",
    "            svc, X, y = train_predict(cspace, channel, svc) \n",
    "else:\n",
    "    svc, X, y = train_predict(global_colour_space, global_channel, svc) \n",
    "            \n",
    "    \n",
    "# X, y = get_features(cspace = global_colour_space, hog_channel=0 )\n",
    "# X_train, X_test, y_train, y_test = split_dataset(X,y)\n",
    "# \n",
    "# # Use a linear SVC \n",
    "# print('creating svc')\n",
    "# svc = LinearSVC()\n",
    "# print('done creating svc')\n",
    "# svc = train_svc(X_train, y_train)\n",
    "# predict_svn(svc)\n",
    "\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc = train_svc(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My SVC predicts: \t [ 0.  1.  0.  0.  1.  1.  0.  1.  1.  0.]\nFor these 10 labels: \t [ 0.  1.  0.  0.  1.  1.  0.  1.  1.  0.]\n0.02106 Seconds to predict 10 labels with SVC\n"
     ]
    }
   ],
   "source": [
    "# n_predict = 10\n",
    "# print('My SVC predicts: \\t', svc.predict(X_test[0:n_predict]))\n",
    "# print('For these',n_predict, 'labels: \\t', y_test[0:n_predict])\n",
    "# t2 = time.time()\n",
    "# print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(filename):\n",
    "    with open(filename, 'wb') as save_file:\n",
    "        pickle.dump(\n",
    "            {   'svc':svc, \n",
    "                # 'scaler': X_scaler,\n",
    "                'orient': orient,\n",
    "                'pix_per_cell': pix_per_cell,       \n",
    "                'cell_per_block': cell_per_block,\n",
    "                'spatial_size': spatial_size,\n",
    "                'hist_bins': hist_bins,\n",
    "            },\n",
    "            save_file, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model('svc_pickle.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start of the sliding window functioality\n",
    "\n",
    "# Define a function you will pass an image \n",
    "# and the list of windows to be searched (output of slide_windows())\n",
    "def search_windows(img, windows, clf, scaler, color_space='RGB', \n",
    "                    spatial_size=(32, 32), hist_bins=32, \n",
    "                    hist_range=(0, 256), orient=9, \n",
    "                    pix_per_cell=8, cell_per_block=2, \n",
    "                    hog_channel=0, spatial_feat=True, \n",
    "                    hist_feat=True, hog_feat=True):\n",
    "\n",
    "    #1) Create an empty list to receive positive detection windows\n",
    "    on_windows = []\n",
    "    #2) Iterate over all windows in the list\n",
    "    for window in windows:\n",
    "        #3) Extract the test window from original image\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))      \n",
    "        #4) Extract features for that window using single_img_features()\n",
    "        features = single_img_features(test_img, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        #5) Scale extracted features to be fed to classifier\n",
    "        test_features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "        #6) Predict using your classifier\n",
    "        prediction = clf.predict(test_features)\n",
    "        #7) If positive (prediction == 1) then save the window\n",
    "        if prediction == 1:\n",
    "            on_windows.append(window)\n",
    "    #8) Return windows for positive detections\n",
    "    return on_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data from files\n",
    "\n",
    "dist_pickle = pickle.load( open(\"./svc_pickle.p\", \"rb\" ) )\n",
    "svc = dist_pickle[\"svc\"]\n",
    "# X_scaler = dist_pickle[\"scaler\"]\n",
    "orient = dist_pickle[\"orient\"]\n",
    "pix_per_cell = dist_pickle[\"pix_per_cell\"]\n",
    "cell_per_block = dist_pickle[\"cell_per_block\"]\n",
    "spatial_size = dist_pickle[\"spatial_size\"]\n",
    "hist_bins = dist_pickle[\"hist_bins\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to draw bounding boxes\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extracted the code to get the searchable portion of the image into its own meth\n",
    "def get_image_to_search(full_img, ystart, ystop):\n",
    "    img_tosearch = full_img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, cspace='RGB2YCrCb')\n",
    "    # plt.imshow(ctrans_tosearch)\n",
    "    return ctrans_tosearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: (720, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "img = mpimg.imread('./test_images/test1.jpg')\n",
    "plt.imshow(img)\n",
    "print('image shape: {}'.format(img.shape))\n",
    "    \n",
    "# ystart = 400\n",
    "# ystop = 656\n",
    "# scale = 1.5\n",
    "# ctrans_tosearch = get_image_to_search(img, ystart, ystop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rect():\n",
    "    def __init__(self, xbox_left, ytop_draw, win_draw):\n",
    "        self.image_raw = False\n",
    "        self.xbox_left = xbox_left\n",
    "        self.ytop_draw = ytop_draw\n",
    "        self.win_draw = win_draw\n",
    "        # create a box variable in the format the heat map expects\n",
    "        self.box = ((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: (720, 1280, 3)\nnblocks_per_window: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\georg\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\skimage\\feature\\_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: (720, 1280, 3)\nnblocks_per_window: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: (720, 1280, 3)\nnblocks_per_window: 7\n"
     ]
    }
   ],
   "source": [
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "def find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins):\n",
    "    \n",
    "\n",
    "    posi_boxes = []\n",
    "    negi_boxes = []\n",
    "    \n",
    "    # print('image shape: {}'.format(img.shape))\n",
    "    \n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    img = img.astype(np.float32)/255\n",
    "    # \n",
    "    # ctrans_tosearch = get_image_to_search(img, ystart, ystop)\n",
    "    # print('image shape: {}'.format(ctrans_tosearch.shape))\n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, cspace=global_colour_space)\n",
    "    \n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    # print('nblocks_per_window: {}' .format(nblocks_per_window))\n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            if (global_channel == 0):\n",
    "                hog_features = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            elif (global_channel == 1):\n",
    "                hog_features = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            elif (global_channel == 2):\n",
    "                hog_features = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            elif(global_channel == 'ALL'):\n",
    "                hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()            \n",
    "                hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "                \n",
    "          \n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            test_prediction = svc.predict(hog_features.reshape(1, -1))    \n",
    "            \n",
    "            xbox_left = np.int(xleft*scale)\n",
    "            ytop_draw = np.int(ytop*scale)\n",
    "            win_draw = np.int(window*scale)\n",
    "            if test_prediction == 1:\n",
    "                # xbox_left = np.int(xleft*scale)\n",
    "                # ytop_draw = np.int(ytop*scale)\n",
    "                # win_draw = np.int(window*scale)\n",
    "                # cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6) \n",
    "                # rect = Rect(xbox_left, ytop_draw, win_draw)\n",
    "                box = ((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart))\n",
    "                posi_boxes.append(box)\n",
    "            else:\n",
    "                box = ((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart))\n",
    "                negi_boxes.append(box)\n",
    "                \n",
    "    for box in negi_boxes:\n",
    "        # xbox_left = rect.xbox_left\n",
    "        # ytop_draw = rect.ytop_draw\n",
    "        # win_draw = rect.win_draw\n",
    "        # cv2.rectangle(draw_img ,(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6)            \n",
    "        cv2.rectangle(draw_img ,box[0],box[1],(0,0,255),6)                                    \n",
    "    \n",
    "    for box in posi_boxes:\n",
    "        # xbox_left = rect.xbox_left\n",
    "        # ytop_draw = rect.ytop_draw\n",
    "        # win_draw = rect.win_draw\n",
    "        # cv2.rectangle(draw_img ,(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart),(255,0,0),6)            \n",
    "        cv2.rectangle(draw_img ,box[0],box[1],(255,0,0),6)       \n",
    "                \n",
    "    return draw_img, posi_boxes, negi_boxes\n",
    "    \n",
    "ystart = 400\n",
    "ystop = 656\n",
    "scale = 1\n",
    "posi_rec_1=[]\n",
    "negi_rec_1=[]\n",
    "out_img_1, posi_boxes_1, negi_boxes_1 = find_cars(img, ystart, ystop, scale, svc, X, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "\n",
    "scale = 1.5\n",
    "posi_rec_15=[]\n",
    "negi_rec_15=[]\n",
    "out_img_15, posi_boxes_15, negi_boxes_15 = find_cars(img, ystart, ystop, scale, svc, X, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "\n",
    "scale = 2\n",
    "posi_rec_2=[]\n",
    "negi_rec_2=[]\n",
    "out_img_2, posi_boxes_2, negi_boxes_2 = find_cars(img, ystart, ystop, scale, svc, X, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "\n",
    "# plt.imshow(out_img)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)\n",
    "plt.subplot(141)\n",
    "plt.imshow(img)\n",
    "plt.title('Input Image')\n",
    "plt.subplot(142)\n",
    "plt.imshow(out_img_1)\n",
    "plt.title('Windows-Scale 1')\n",
    "plt.subplot(143)\n",
    "plt.imshow(out_img_15)\n",
    "plt.title('Windows-Scale 1.5')\n",
    "plt.subplot(144)\n",
    "plt.imshow(out_img_2)\n",
    "plt.title('Windows-Scale 2')\n",
    "# fig.tight_layout()\n",
    "plt.savefig('./output_images/windows_all.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_posi_rec =  posi_boxes_1 + posi_boxes_15 + posi_boxes_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bbox_pickle.p'\n",
    "with open(filename, 'wb') as save_file:\n",
    "    pickle.dump( all_posi_rec, open( filename, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a pickle file with bboxes saved\n",
    "# Each item in the \"all_bboxes\" list will contain a \n",
    "# list of boxes for one of the images shown above\n",
    "all_posi_boxes = pickle.load( open( \"bbox_pickle.p\", \"rb\" ))\n",
    "\n",
    "# # Read in image similar to one shown above \n",
    "# image = mpimg.imread('test_image.jpg')\n",
    "# heat = np.zeros_like(image[:,:,0]).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_heat(heatmap, boxes):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in boxes:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap# Iterate through list of bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bb_via_heat(img, boxes):\n",
    "\n",
    "    heat = np.zeros_like(np.copy(img[:,:,0]))\n",
    "    \n",
    "    # Add heat to each box in box list\n",
    "    heat = add_heat(heat, boxes)\n",
    "        \n",
    "    # Apply threshold to help remove false positives\n",
    "    heat = apply_threshold(heat,1)\n",
    "    \n",
    "    # Visualize the heatmap when displaying    \n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "    \n",
    "    # Find final boxes from heatmap using label function\n",
    "    labels = label(heatmap)\n",
    "    draw_img = draw_labeled_bboxes(np.copy(img), labels)\n",
    "    return draw_img, heatmap\n",
    "\n",
    "\n",
    "draw_img, heatmap = get_bb_via_heat(img, all_posi_boxes)    \n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(draw_img)\n",
    "plt.title('Car Positions')\n",
    "plt.subplot(122)\n",
    "plt.imshow(heatmap, cmap='hot')\n",
    "plt.title('Heat Map')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to process an image \n",
    "def process_image(img):\n",
    "    ystart = 400\n",
    "    ystop = 656\n",
    "    scale = 1\n",
    "    posi_rec_1=[]\n",
    "    negi_rec_1=[]\n",
    "    out_img_1, posi_boxes_1, negi_boxes_1 = find_cars(img, ystart, ystop, scale, svc, X, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    \n",
    "    scale = 1.5\n",
    "    posi_rec_15=[]\n",
    "    negi_rec_15=[]\n",
    "    out_img_15, posi_boxes_15, negi_boxes_15 = find_cars(img, ystart, ystop, scale, svc, X, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    \n",
    "    scale = 2\n",
    "    posi_rec_2=[]\n",
    "    negi_rec_2=[]\n",
    "    out_img_2, posi_boxes_2, negi_boxes_2 = find_cars(img, ystart, ystop, scale, svc, X, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "\n",
    "    all_posi_boxes =  posi_boxes_1 + posi_boxes_15 + posi_boxes_2\n",
    "    draw_img, heatmap = get_bb_via_heat(img, all_posi_boxes) \n",
    "    processed_img = process_image(img)\n",
    "    return processed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the test images and call the process image method\n",
    "\n",
    "test_image_files = glob.glob('./test_images/*.jpg')\n",
    "processed_imgs = []\n",
    "fig = plt.figure()\n",
    "subplot_ind = 211\n",
    "for file in test_image_files:\n",
    "    print ('processing file: {}' .format(file))\n",
    "    # processed_imgs.append(process_image(img))\n",
    "    img = mpimg.imread(file)\n",
    "    plt.subplot(subplot_ind)\n",
    "    subplot_ind += 1\n",
    "    processed_img = process_image(img)\n",
    "\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}